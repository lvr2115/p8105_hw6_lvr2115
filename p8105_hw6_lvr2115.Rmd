---
title: "Homework 6 - lvr2115"
author: "Laura Robles-Torres"
date: "2023-11-30"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load packages, message=FALSE}
library(modelr)
library(tidyverse)
library(mgcv)
library(p8105.datasets)

set.seed(1)
```

# Problem 2

```{r import data, message=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

This code creates a multiple linear regression model with 'tmax' as the response with 'tmin' and 'prcp' as the predictors. 

```{r}
fit = lm(tmax ~ tmin + prcp, data = weather_df)

fit |> 
  broom::glance()

fit |>
  broom::tidy()
```

## Distribution of R-squared

This code uses 5000 bootstrap samples to plot the *distribution of R-squared.*

```{r dist of r squared with plot}
#bootstrapping
weather_r2 = 
  weather_df |> 
    modelr::bootstrap(n = 5000, id="strap_number") |> 
    mutate(
     models = map(.x=strap, ~lm(tmax ~ tmin + prcp, data = .x)),
     results = map(.x=models, broom::glance)) |> 
    select(strap_number, results) |>
    unnest(results) 

#plot
weather_r2 |> 
  ggplot(aes(x = r.squared)) + geom_density()

#confidence intervals
weather_r2|>
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))
```

The graph shows a left-skewed distribution of R-squared with the curve peaking at around 0.920 in a graph ranging from 0.850 to 0.950. The 95% confidence interval is (0.889,	0.941).

## Distribution of log of beta1*beta2

This code uses 5000 bootstrap samples to plot the *distribution of log(beta 1  times beta2).*

```{r dist of log of b1*b2 with plot, warning=FALSE}
#bootstrapping

weather_log =
  weather_df |> 
    modelr::bootstrap(n = 5000, id="strap_number") |> 
     mutate(
      models = map(.x=strap, ~lm(tmax ~ tmin + prcp, data = .x)),
      results = map(models, broom::tidy))|>
    select(strap_number, results)|>
    unnest(results) |> 
    pivot_wider(
      names_from = term, 
      values_from = estimate) |>
    group_by(strap_number) |>
    summarize(
     tmin = first(na.omit(tmin)),
     prcp = first(na.omit(prcp)),
     log_product = log(tmin * prcp)
    )

#plot
weather_log |>
  filter(log_product!="NaN") |>
  ggplot(aes(x=log_product))+geom_density()

#confidence intervals 
ci_log_product =
  weather_log |> 
  summarize(
    ci_lower = quantile(log_product, 0.025, na.rm=TRUE),
    ci_upper = quantile(log_product, 0.975,na.rm=TRUE)
  )
```

The distribution of log(tmin*prcp) is also remarkably left-skewed with the curve peaking at around -5.5 on a graph of range -13 to -4. The 95% confidence interval is (-8.947,-4.571). 

# Problem 3

```{r import and clean data, message=FALSE}
birthweight = 
  read_csv("./birthweight.csv") |>
  janitor::clean_names(case="snake") |>
  drop_na() |>
  filter(malform!=1) |>
  mutate(
    id = row_number(),
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    malform = as.factor(malform),
    mrace = as.factor(mrace))
```

## Proposing a model

I propose that the predictors that could affect bw and should be in my model are: gestational age at birth (gaweeks), mother's pre-pregnancy BMI (ppbmi), maternal race (mrace) and average number of cigarettes smoked per day during pregnancy (smoken). I removed observations in my dataset in which there is a malformation that could affect birthweight present, as there are only 15 observations in which there is a malformation and I would consider them outliers in this case as malformations are not a predictor of interest. 

```{r}
model =lm(bwt~gaweeks+ppbmi+mrace+smoken, data=birthweight)
model2= lm(bwt~blength+gaweeks, data = birthweight)
model3= lm(bwt~bhead*blength + bhead*babysex + blength*babysex, data=birthweight)
```

### Plot model residuals vs. fitted values for my proposed model (model 1)

```{r}
birthweight |> 
  add_predictions(model1) |>
  add_residuals(model1) |>
  ggplot(aes(x = pred, y = resid)) +  geom_point() +
  geom_smooth(method = "lm") +
  labs(
    title = "Residuals vs Fitted Values ")
```

*The slope of this line is ~0, as indicated by the fact it appears horizontal. This indicates a lack of relationship between residuals and predictors and confirms that we can assume homoscedasticity as the variance of the residuals is approximately constant across all levels of the predicted values.*


```{r plot of model residuals vs fitted values}
modelr::add_residuals(birthweight, model) |>
  ggplot(aes(x = babysex, y = resid)) + geom_violin() +
  facet_wrap(.~frace)

modelr::add_residuals(birthweight, fit) |>
  ggplot(aes(x = gaweeks, y = resid)) + geom_violin() +
  facet_wrap(.~frace)
```

## Comparing to other models using CV

```{r}
cv_df =
  crossv_mc(birthweight, 80)  #80 cross validation runs

cv_df = 
  cv_df |> 
  mutate(
    model1  = map(.x = train, ~lm(bwt~gaweeks+ppbmi+mrace+smoken, data = .x)),
    model2  = map(.x = train, ~lm(bwt~blength+gaweeks, data = .x)),
    model3  = map(.x = train, ~lm(bwt~bhead*blength + bhead*babysex + blength*babysex, data = .x))) |>
  mutate(
    rmse_model= map2_dbl(.x=model1, .y=test, ~rmse(model = .x, data = .y)),
    rmse_model2= map2_dbl(.x=model2, .y=test, ~rmse(model = .x, data = .y)),
    rmse_model3 = map2_dbl(.x=model3, .y=test, ~rmse(model = .x, data = .y)) 
  ) 

summary(model1)
```


```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(
    model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

*Based on this graph displaying the RMSE of each model, I would conclude that model #3 with interaction terms has the lowest RMSE. 
